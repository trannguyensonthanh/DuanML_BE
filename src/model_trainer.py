# src/model_trainer.py
import os
import cv2
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from .feature_extractor import FeatureExtractor
from .utils import setup_logger

logger = setup_logger("Trainer")

class TrashClassifier:
    def __init__(self, data_dir, model_path="models/best_tuned_ensemble_model.pkl"):
        self.data_dir = data_dir
        self.model_path = model_path
        self.extractor = FeatureExtractor()
        self.label_encoder = LabelEncoder()
        
    def load_and_extract_features(self):
        """ƒê·ªçc ·∫£nh t·ª´ folder processed v√† bi·∫øn ƒë·ªïi th√†nh vector s·ªë."""
        X = []
        y = []
        if not os.path.exists(self.data_dir):
            logger.error(f"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {self.data_dir}")
            return np.array([]), np.array([])
        classes = sorted(os.listdir(self.data_dir))
        total_files = sum([len(files) for r, d, files in os.walk(self.data_dir)])
        logger.info(f"‚è≥ T√¨m th·∫•y {total_files} ·∫£nh. B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng n√¢ng cao...")
        with tqdm(total=total_files, desc="Extracting Advanced Features", unit="img") as pbar:
            for label in classes:
                class_path = os.path.join(self.data_dir, label)
                if not os.path.isdir(class_path): continue
                files = os.listdir(class_path)
                for file_name in files:
                    img_path = os.path.join(class_path, file_name)
                    img = cv2.imread(img_path)
                    if img is None: 
                        pbar.update(1)
                        continue
                    vector = self.extractor.extract(img)
                    if vector is not None:
                        X.append(vector)
                        y.append(label)
                    pbar.update(1)
        logger.info(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t xong. T·ªïng m·∫´u h·ª£p l·ªá: {len(X)}")
        return np.array(X, dtype=np.float32), np.array(y)

    def train(self):
        # 1. Chu·∫©n b·ªã d·ªØ li·ªáu
        X, y_text = self.load_and_extract_features()
        
        if len(X) == 0:
            logger.error("D·ªØ li·ªáu r·ªóng! H√£y ki·ªÉm tra l·∫°i folder data/processed")
            return

        y = self.label_encoder.fit_transform(y_text)
        
        if not os.path.exists("models"): os.makedirs("models")
        joblib.dump(self.label_encoder, "models/label_encoder.pkl")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # 2. [N√ÇNG C·∫§P SERVER] X√¢y d·ª±ng Ensemble Model v·ªõi Pipeline linh ho·∫°t
        logger.info("üèõÔ∏è  ƒêang x√¢y d·ª±ng 'H·ªôi ƒë·ªìng chuy√™n gia' (Ensemble)...")

        # T·∫°o c√°c pipeline ri√™ng l·∫ª
        svm_pipeline = Pipeline([('scaler_svm', StandardScaler()), ('pca', PCA(n_components=0.98)), ('clf', SVC(probability=True, class_weight='balanced'))])
        rf_pipeline = Pipeline([('scaler_rf', StandardScaler()), ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))])
        gb_pipeline = Pipeline([('scaler_gb', StandardScaler()), ('clf', GradientBoostingClassifier(random_state=42))])

        # K·∫øt h·ª£p th√†nh VotingClassifier
        ensemble_model = VotingClassifier(
            estimators=[
                ('svm', svm_pipeline),
                ('rf', rf_pipeline),
                ('gb', gb_pipeline)
            ],
            voting='soft'
        )

        # 3. [N√ÇNG C·∫§P SERVER] ƒê·ªãnh nghƒ©a kh√¥ng gian t√¨m ki·∫øm SI√äU KH·ªîNG L·ªí cho GridSearchCV
        # C√∫ ph√°p: 't√™n_estimator__t√™n_b∆∞·ªõc__t√™n_tham_s·ªë'
        param_grid = {
            'svm__clf__C': [10, 100, 500],
            'svm__clf__gamma': ['scale', 0.01],
            'rf__clf__n_estimators': [200, 300],
            'rf__clf__max_depth': [20, 30],
            'gb__clf__n_estimators': [200, 300],
            'gb__clf__learning_rate': [0.1, 0.05]
        }
        
        # 4. [N√ÇNG C·∫§P SERVER] Ch·∫°y GridSearchCV v·ªõi to√†n b·ªô s·ª©c m·∫°nh CPU
        logger.info("üöÄ B·∫Øt ƒë·∫ßu GridSearch TO√ÄN DI·ªÜN tr√™n Ensemble Model...")
        logger.info(f"   S·ª≠ d·ª•ng t·∫•t c·∫£ c√°c nh√¢n CPU c√≥ s·∫µn. Qu√° tr√¨nh n√†y s·∫Ω r·∫•t l√¢u!")
        
        # cv=3 ƒë·ªÉ gi·∫£m th·ªùi gian so v·ªõi cv=5, nh∆∞ng v·∫´n ƒë·∫£m b·∫£o ƒë·ªô tin c·∫≠y
        # verbose=3 ƒë·ªÉ theo d√µi ti·∫øn tr√¨nh chi ti·∫øt
        grid_search = GridSearchCV(
            estimator=ensemble_model,
            param_grid=param_grid,
            cv=3, 
            scoring='accuracy',
            n_jobs=-1, # <-- T·∫¨N D·ª§NG T·∫§T C·∫¢ 20 CORES CPU
            verbose=3
        )
        
        grid_search.fit(X_train, y_train)
        
        best_model = grid_search.best_estimator_
        logger.info(f"üéØ Tham s·ªë t·ªët nh·∫•t t√¨m ƒë∆∞·ª£c: {grid_search.best_params_}")
        logger.info(f"üìà ƒê·ªô ch√≠nh x√°c t·ªët nh·∫•t tr√™n t·∫≠p validation: {grid_search.best_score_*100:.2f}%")
        
        # 5. ƒê√°nh gi√° model t·ªët nh·∫•t tr√™n t·∫≠p Test
        logger.info("üìä ƒêang ƒë√°nh gi√° model T·ªêT NH·∫§T tr√™n t·∫≠p Test...")
        y_pred = best_model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        
        print("\n" + "="*40)
        print(f"üèÜ ƒê·ªò CH√çNH X√ÅC CU·ªêI C√ôNG (TUNED ENSEMBLE): {acc*100:.2f}%")
        print("="*40)
        print("\nB√ÅO C√ÅO CHI TI·∫æT:")
        print(classification_report(y_test, y_pred, target_names=self.label_encoder.classes_))
        
        self.plot_confusion_matrix(y_test, y_pred, self.label_encoder.classes_)
        
        # L∆∞u model t·ªët nh·∫•t
        joblib.dump(best_model, self.model_path)
        logger.info(f"üíæ Model Ensemble ƒë√£ Tinh ch·ªânh ƒë∆∞·ª£c l∆∞u t·∫°i: {self.model_path}")

    def plot_confusion_matrix(self, y_true, y_pred, classes):
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=classes, yticklabels=classes)
        plt.title('Confusion Matrix')
        plt.ylabel('Th·ª±c t·∫ø (Ground Truth)')
        plt.xlabel('D·ª± ƒëo√°n (Prediction)')
        plt.savefig('models/confusion_matrix.png')
        plt.close()