# src/evaluator.py
import os
import cv2
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, top_k_accuracy_score

# Import t·ª´ c√°c module ƒë√£ t·ªëi ∆∞u tr∆∞·ªõc ƒë√≥
from .feature_extractor import FeatureExtractor
from .utils import setup_logger, ensure_dir

# C·∫•u h√¨nh giao di·ªán bi·ªÉu ƒë·ªì chuy√™n nghi·ªáp
sns.set_theme(style="whitegrid")
logger = setup_logger("EvaluatorPro")


class GoldEvaluator:
    def __init__(self, model_path, encoder_path, test_dir, output_dir):
        """
        Kh·ªüi t·∫°o b·ªô ƒë√°nh gi√° cao c·∫•p.
        T∆∞∆°ng th√≠ch v·ªõi: PyTorch CLAHE + Logistic Regression
        """
        self.test_dir = test_dir
        self.output_dir = output_dir
        self.error_dir = os.path.join(output_dir, "errors_gallery")
        self.plots_dir = os.path.join(output_dir, "analysis_plots")

        ensure_dir(self.output_dir)
        ensure_dir(self.error_dir)
        ensure_dir(self.plots_dir)

        # 1. Load Model Pipeline & Label Encoder
        logger.info(f"‚è≥ ƒêang t·∫£i 'brain' (Model) t·ª´: {model_path}")
        if not os.path.exists(model_path) or not os.path.exists(encoder_path):
            raise FileNotFoundError("CRITICAL ERROR: Kh√¥ng t√¨m th·∫•y model ho·∫∑c label encoder. H√£y train tr∆∞·ªõc!")

        self.model = joblib.load(model_path)
        self.le = joblib.load(encoder_path)
        self.classes = self.le.classes_

        logger.info("‚è≥ ƒêang kh·ªüi t·∫°o Feature Extractor (CLAHE)...")
        self.extractor = FeatureExtractor()

    def _parse_polygon(self, line, img_w, img_h):
        """ƒê·ªçc chu·ªói t·ªça ƒë·ªô Polygon YOLO v√† chu·∫©n h√≥a."""
        try:
            parts = list(map(float, line.strip().split()))
            coords = parts[1:]  # B·ªè class_id
            if len(coords) < 6: return None
            points = []
            for i in range(0, len(coords), 2):
                x = int(coords[i] * img_w)
                y = int(coords[i + 1] * img_h)
                points.append([x, y])
            return np.array(points, dtype=np.int32)
        except Exception:
            return None

    def _crop_and_mask(self, img, polygon):
        """
        K·ª∏ THU·∫¨T T√ÅCH N·ªÄN (MASKING):
        T√¥ ƒëen to√†n b·ªô background, ch·ªâ gi·ªØ l·∫°i v·∫≠t th·ªÉ trong polygon.
        """
        mask = np.zeros(img.shape[:2], dtype=np.uint8)
        cv2.fillPoly(mask, [polygon], 255)

        # Bitwise AND ƒë·ªÉ x√≥a n·ªÅn
        masked_img = cv2.bitwise_and(img, img, mask=mask)

        # C·∫Øt khung h√¨nh ch·ªØ nh·∫≠t bao quanh polygon
        x, y, w, h = cv2.boundingRect(polygon)
        crop = masked_img[y:y + h, x:x + w]
        return crop

    def run(self):
        logger.info(f"üöÄ B·∫Øt ƒë·∫ßu quy tr√¨nh ki·ªÉm th·ª≠ tr√™n t·∫≠p: {self.test_dir}")

        results_data = []  # L∆∞u data ƒë·ªÉ xu·∫•t CSV
        y_true_all = []
        y_probs_all = []  # L∆∞u x√°c su·∫•t ƒë·ªÉ t√≠nh Top-K

        folder_classes = sorted(os.listdir(self.test_dir))

        # Duy·ªát qua t·ª´ng folder class th·∫≠t (Ground Truth)
        for true_label_str in folder_classes:
            class_path = os.path.join(self.test_dir, true_label_str)
            if not os.path.isdir(class_path): continue

            image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

            for img_name in tqdm(image_files, desc=f"Testing {true_label_str}"):
                img_path = os.path.join(class_path, img_name)
                txt_path = os.path.splitext(img_path)[0] + ".txt"

                # B·∫Øt bu·ªôc ph·∫£i c√≥ file nh√£n Polygon
                if not os.path.exists(txt_path): continue

                img = cv2.imread(img_path)
                if img is None: continue
                h_img, w_img = img.shape[:2]

                with open(txt_path, 'r') as f:
                    lines = f.readlines()

                # X·ª≠ l√Ω t·ª´ng object trong ·∫£nh (th∆∞·ªùng l√† 1)
                for idx, line in enumerate(lines):
                    # 1. Parse Polygon & Masking
                    polygon = self._parse_polygon(line, w_img, h_img)
                    if polygon is None: continue

                    try:
                        crop_masked = self._crop_and_mask(img, polygon)
                    except Exception:
                        continue

                    if crop_masked.size == 0 or crop_masked.shape[0] < 10: continue

                    # 2. Feature Extraction (Tr·ª±c ti·∫øp t·ª´ ·∫£nh crop)
                    # FeatureExtractor s·∫Ω t·ª± ƒë·ªông Resize -> CLAHE -> ResNet
                    features = self.extractor.extract(crop_masked)

                    if features is None: continue

                    # 3. Prediction (D·ª± ƒëo√°n)
                    features = features.reshape(1, -1)

                    # L·∫•y x√°c su·∫•t
                    probs = self.model.predict_proba(features)[0]

                    # L·∫•y class c√≥ x√°c su·∫•t cao nh·∫•t
                    pred_idx = np.argmax(probs)
                    pred_label_str = self.le.inverse_transform([pred_idx])[0]
                    confidence = probs[pred_idx]

                    # L·∫•y Top-2 Prediction (ƒê·ªÉ xem n·∫øu sai th√¨ c√≥ su√Ωt ƒë√∫ng kh√¥ng)
                    top2_idx = np.argsort(probs)[-2:][::-1]
                    top2_labels = self.le.inverse_transform(top2_idx)

                    # 4. Ghi nh·∫≠n d·ªØ li·ªáu
                    is_correct = (true_label_str == pred_label_str)

                    y_true_all.append(true_label_str)
                    y_probs_all.append(probs)

                    # T·∫°o record chi ti·∫øt cho CSV
                    record = {
                        "Image": img_name,
                        "Ground_Truth": true_label_str,
                        "Prediction": pred_label_str,
                        "Confidence": round(confidence * 100, 2),
                        "Is_Correct": is_correct,
                        "Top_2_Guess": f"{top2_labels[1]} ({round(probs[top2_idx[1]] * 100, 2)}%)"
                    }
                    # Th√™m x√°c su·∫•t t·ª´ng class v√†o CSV
                    for i, cls_name in enumerate(self.classes):
                        record[f"Prob_{cls_name}"] = round(probs[i], 4)

                    results_data.append(record)

                    # 5. L∆∞u ·∫£nh sai (Error Analysis Gallery)
                    if not is_correct:
                        err_fname = f"Err_True[{true_label_str}]_Pred[{pred_label_str}]_Conf[{int(confidence * 100)}]_{img_name}"

                        # V·∫Ω th√™m text l√™n ·∫£nh ƒë·ªÉ debug
                        debug_img = crop_masked.copy()  # D√πng ·∫£nh crop ƒë·ªÉ d·ªÖ nh√¨n v·∫≠t th·ªÉ
                        debug_img = cv2.resize(debug_img, (256, 256))

                        # Apply CLAHE l√™n ·∫£nh debug ƒë·ªÉ ng∆∞·ªùi xem d·ªÖ nh√¨n chi ti·∫øt nh∆∞ m√°y nh√¨n
                        lab = cv2.cvtColor(debug_img, cv2.COLOR_BGR2LAB)
                        l, a, b = cv2.split(lab)
                        l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(l)
                        debug_img = cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2BGR)

                        cv2.putText(debug_img, f"True: {true_label_str}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                                    (0, 255, 0), 2)
                        cv2.putText(debug_img, f"Pred: {pred_label_str}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                                    (0, 0, 255), 2)

                        cv2.imwrite(os.path.join(self.error_dir, err_fname), debug_img)

        # --- T·ªîNG H·ª¢P V√Ä B√ÅO C√ÅO ---
        if not results_data:
            logger.error("‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu test n√†o h·ª£p l·ªá (ho·∫∑c l·ªói file txt)!")
            return

        df = pd.DataFrame(results_data)

        # 1. T√≠nh to√°n Metrics
        y_pred_all = df["Prediction"].values
        acc = accuracy_score(y_true_all, y_pred_all)

        # Top-2 Accuracy
        y_true_indices = self.le.transform(y_true_all)
        top2_acc = top_k_accuracy_score(y_true_indices, np.array(y_probs_all), k=2, labels=np.arange(len(self.classes)))

        print("\n" + "‚ïê" * 60)
        print(f"üìä REPORT K·∫æT QU·∫¢ KI·ªÇM TH·ª¨ (POLYGON DATASET)")
        print("‚ïê" * 60)
        print(f"üèÜ Top-1 Accuracy (Ch√≠nh x√°c tuy·ªát ƒë·ªëi):  {acc * 100:.2f}%")
        print(f"ü•à Top-2 Accuracy (ƒê√°p √°n ƒë√∫ng n·∫±m trong Top 2): {top2_acc * 100:.2f}%")
        print("-" * 60)
        print(classification_report(y_true_all, y_pred_all))
        print("‚ïê" * 60)

        # 2. Xu·∫•t CSV
        csv_path = os.path.join(self.output_dir, "FULL_Evaluation_Report.csv")
        df.to_csv(csv_path, index=False)
        logger.info(f"üìÑ ƒê√£ xu·∫•t b√°o c√°o chi ti·∫øt t·∫°i: {csv_path}")

        # 3. V·∫Ω bi·ªÉu ƒë·ªì
        self._visualize_performance(y_true_all, y_pred_all, df)

    def _visualize_performance(self, y_true, y_pred, df):
        """V·∫Ω c√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch chuy√™n s√¢u."""

        # A. Confusion Matrix Heatmap
        cm = confusion_matrix(y_true, y_pred, labels=self.classes)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=self.classes, yticklabels=self.classes)
        plt.title('Confusion Matrix (Ma tr·∫≠n nh·∫ßm l·∫´n)')
        plt.ylabel('Th·ª±c t·∫ø')
        plt.xlabel('D·ª± ƒëo√°n')
        plt.tight_layout()
        plt.savefig(os.path.join(self.plots_dir, "1_Confusion_Matrix.png"))
        plt.close()

        # B. Confidence Distribution
        plt.figure(figsize=(10, 6))
        sns.histplot(data=df, x="Confidence", hue="Is_Correct", multiple="stack", bins=20, kde=True)
        plt.title("Ph√¢n ph·ªëi ƒë·ªô tin c·∫≠y c·ªßa d·ª± ƒëo√°n (ƒê√∫ng vs Sai)")
        plt.xlabel("ƒê·ªô tin c·∫≠y (Confidence Score %)")
        plt.ylabel("S·ªë l∆∞·ª£ng ·∫£nh")
        plt.savefig(os.path.join(self.plots_dir, "2_Confidence_Distribution.png"))
        plt.close()

        logger.info(f"üìä ƒê√£ l∆∞u c√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch t·∫°i: {self.plots_dir}")